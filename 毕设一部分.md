[toc]

# Beyond Photometric Loss for Self-Supervised Ego-Motion Estimation

* 目的：弥合几何损失和光度损失
* 模型：自监督学习
* 数据集：KITTI
* 方法：结合传统单目 SLAM 的准确中间几何表示 和 自监督深度估计，为联合深度与运动估计提供一个更好的公式
* 输入：三个相邻帧
* 输出：目标帧的预测深度图和相对位姿

## 一、介绍

受生物相似性启发，深度和相对运动的联合推断引起关注。

涉及深度和运动的相互作用的两种信息来源：

1. 来自图像强度和色彩等光度信息
2. 从稳定的局部关键点计算的几何信息

现有的无监督或自监督方法基于光度一致性的图像重建误差。虽不需要大量标记数据，但假设：

* 场景为静态，无移动对象
* 目标视图与原视图之间无遮挡
* 表面是Lambertian的

自生成的几何量可以隐式嵌入到训练过程而不打破推断的简单性。所以探索了中间几何信息，以改进深度与运动的联合优化。

## 二、相关工作

###2.1 传统的视觉 SLAM 方法

间接法和直接法，自监督学习框架源自直接法

###2.2 从数据中学习深度和位姿

大多数深度估计依赖于深度传感器的监督。

自监督法基于扭曲的视图合成，但假设场景是静态的，且相机经过仔细校准消除了光度失真。

提出将几何损失引入自监督深度和相对位姿估计问题。

## 三、方法

### 3.1 概述

用平滑项解决运动估计中的梯度局部问题，并消除低纹理区中学习深度的不连续性。

### 3.2 对极几何的几何误差

**描述子具有由尺度空间理论保证的强不变性。这些几何成分可以离线预处理并隐式集成到 CNN 中。**

### 3.3 其他弱对极几何监督

为将几何损失纳入自监督框架，除使用对极几何外，间接法还提供其他如 PnP 方法计算相机位姿。

两种合并弱监督的方法：

1. **Direct-Weak-Pose**
2. **Prior-Weak-Pose**

### 3.4 修正光度误差

由于遮挡和动态对象普遍存在，直接使用光度误差会造成较大误差。设置了一个掩膜（Mask），超过该光度误差的阈值的话就不计入损失函数。阈值是动态的（让有效像素值达到$99\%$）。

## 四、实验

### 4.1 数据集

使用KITTI，用Eigen Split 测试单目深度，用里程计序列评估视觉里程计性能。所有使用的图像采用立体对的左侧单目相机并下采样。

### 4.2 实施细则

使用 SIFT 描述子进行特征匹配，使用立体图而不是单目视图，因为立体图更准确。随机抽取100个匹配特征进行训练

使用 TensorFlow 框架， Adam 算法求解。深度和位姿网络都使用 ResNet-50。

### 4.3 消融研究

大体是采用控制变量法，去掉原结构的一部分看剩余部分能不能正常工作。

## 五、结论

首先分析目前自监督深度和运动估计的损失公式具有局限性，所以提出将中间几何计算（如特征匹配）融合到自监督学习框架中。是初步探索。

未来方向：

* 在较长的图像序列中融合几何量
* 融合传统和学习方法
